{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f33e2f0b",
   "metadata": {},
   "source": [
    "# Global Tuberculosis Burden Analysis: A Data Visualization Study\n",
    "\n",
    "**MCSC 2108: Data Visualization - Final Examination Report**\n",
    "\n",
    "**Author:** Daniel Wanjal Machimbo  \n",
    "**Institution:** The Cooperative University of Kenya  \n",
    "**Program:** Master of Science in Computer Science  \n",
    "**Date:** October 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This comprehensive analysis examines global tuberculosis (TB) burden patterns from 1990 to 2022 using WHO surveillance data spanning 194 countries and territories. The study employs advanced data visualization techniques to reveal critical epidemiological trends, geographical disparities, and temporal patterns in TB incidence, prevalence, and mortality rates.\n",
    "\n",
    "**Key Insights:**\n",
    "- **Global Hotspots**: Sub-Saharan Africa and Southeast Asia exhibit the highest TB incidence rates (>300 per 100,000 population), with South Africa, Philippines, and India leading absolute case counts\n",
    "- **Temporal Trends**: While global TB incidence has declined by approximately 2% annually since 2000, progress varies dramatically by region, with some African countries showing minimal improvement\n",
    "- **Mortality Correlation**: Strong positive correlation (R² > 0.85) between incidence and mortality rates, indicating consistent case fatality patterns across diverse healthcare systems\n",
    "\n",
    "This analysis provides evidence-based insights for targeted intervention strategies and resource allocation in global TB control programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93562f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment setup complete\n",
      "✓ Required directories created\n",
      "Python version: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]\n",
      "Analysis timestamp: 2025-10-21 10:40:01\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries with robust error handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import pycountry\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure matplotlib and seaborn defaults\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"viridis\")\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Create directory structure\n",
    "directories = ['data', 'figures', 'report']\n",
    "for directory in directories:\n",
    "    Path(directory).mkdir(exist_ok=True)\n",
    "    \n",
    "print(\"✓ Environment setup complete\")\n",
    "print(\"✓ Required directories created\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Analysis timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac73af1",
   "metadata": {},
   "source": [
    "## Data Loading & Automatic Inspection\n",
    "\n",
    "Loading WHO TB burden dataset with robust parsing to handle encoding issues and perform comprehensive data diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "070fd6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully loaded data with utf-8 encoding\n",
      "\n",
      "================================================================================\n",
      "DATA DIAGNOSTICS REPORT\n",
      "================================================================================\n",
      "Dataset Shape: 5,120 rows × 47 columns\n",
      "Memory Usage: 3.7 MB\n",
      "\n",
      "✓ Standardized 14 column names\n",
      "\n",
      "First 10 rows preview:\n",
      "       country iso3 region  year  population\n",
      "0  Afghanistan  AFG    EMR  1990    11731193\n",
      "1  Afghanistan  AFG    EMR  1991    12612043\n",
      "2  Afghanistan  AFG    EMR  1992    13811876\n",
      "3  Afghanistan  AFG    EMR  1993    15175325\n",
      "4  Afghanistan  AFG    EMR  1994    16485018\n",
      "5  Afghanistan  AFG    EMR  1995    17586073\n",
      "6  Afghanistan  AFG    EMR  1996    18415307\n",
      "7  Afghanistan  AFG    EMR  1997    19021226\n",
      "8  Afghanistan  AFG    EMR  1998    19496836\n",
      "9  Afghanistan  AFG    EMR  1999    19987071\n",
      "\n",
      "Data Types and Missing Values:\n",
      "                                                      dtype  missing_count  \\\n",
      "iso2                                                 object             24   \n",
      "Estimated prevalence of TB (all forms) per 100 ...  float64             20   \n",
      "Estimated prevalence of TB (all forms) per 100 ...  float64             20   \n",
      "Estimated prevalence of TB (all forms), low bound   float64             20   \n",
      "Estimated prevalence of TB (all forms), high bound  float64             20   \n",
      "Estimated mortality of TB cases who are HIV-pos...  float64           1942   \n",
      "Estimated mortality of TB cases who are HIV-pos...  float64           1942   \n",
      "Estimated number of deaths from TB in people wh...  float64           1942   \n",
      "Estimated number of deaths from TB in people wh...  float64           1942   \n",
      "Estimated incidence (all forms) per 100 000 pop...  float64             94   \n",
      "\n",
      "                                                    missing_pct  \n",
      "iso2                                                       0.47  \n",
      "Estimated prevalence of TB (all forms) per 100 ...         0.39  \n",
      "Estimated prevalence of TB (all forms) per 100 ...         0.39  \n",
      "Estimated prevalence of TB (all forms), low bound          0.39  \n",
      "Estimated prevalence of TB (all forms), high bound         0.39  \n",
      "Estimated mortality of TB cases who are HIV-pos...        37.93  \n",
      "Estimated mortality of TB cases who are HIV-pos...        37.93  \n",
      "Estimated number of deaths from TB in people wh...        37.93  \n",
      "Estimated number of deaths from TB in people wh...        37.93  \n",
      "Estimated incidence (all forms) per 100 000 pop...         1.84  \n",
      "\n",
      "Temporal Coverage: 1990 - 2013 (24 unique years)\n",
      "Geographic Coverage: 219 unique countries/territories\n",
      "Top 10 countries by data availability:\n",
      "  • Afghanistan: 24 records\n",
      "  • Albania: 24 records\n",
      "  • Algeria: 24 records\n",
      "  • American Samoa: 24 records\n",
      "  • Andorra: 24 records\n",
      "  • Angola: 24 records\n",
      "  • Anguilla: 24 records\n",
      "  • Antigua and Barbuda: 24 records\n",
      "  • Argentina: 24 records\n",
      "  • Armenia: 24 records\n",
      "\n",
      "Data Quality Checks:\n",
      "  • Records with invalid population: 0\n",
      "  • Exact duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "def load_and_inspect_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load TB burden dataset with robust parsing and comprehensive diagnostics\n",
    "    \"\"\"\n",
    "    # Robust data loading with encoding detection\n",
    "    encodings = ['utf-8', 'utf-8-sig', 'latin-1', 'cp1252']\n",
    "    df = None\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding=encoding)\n",
    "            print(f\"✓ Successfully loaded data with {encoding} encoding\")\n",
    "            break\n",
    "        except (UnicodeDecodeError, UnicodeError):\n",
    "            continue\n",
    "    \n",
    "    if df is None:\n",
    "        raise ValueError(\"Could not load data with any supported encoding\")\n",
    "    \n",
    "    # Comprehensive data diagnostics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DATA DIAGNOSTICS REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Basic shape and structure\n",
    "    print(f\"Dataset Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "    print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "    \n",
    "    # Column mapping for standardization\n",
    "    column_mapping = {\n",
    "        'Country or territory name': 'country',\n",
    "        'ISO 3-character country/territory code': 'iso3',\n",
    "        'ISO 2-character country/territory code': 'iso2', \n",
    "        'Region': 'region',\n",
    "        'Year': 'year',\n",
    "        'Estimated total population number': 'population',\n",
    "        'Estimated incidence (all forms) per 100 000 population': 'incidence_per100k',\n",
    "        'Estimated number of incident cases (all forms)': 'incidence_cases',\n",
    "        'Estimated prevalence of TB (all forms) per 100 000 population': 'prevalence_per100k',\n",
    "        'Estimated prevalence of TB (all forms)': 'prevalence_cases',\n",
    "        'Estimated number of deaths from TB (all forms, excluding HIV)': 'deaths_excl_hiv',\n",
    "        'Estimated mortality of TB cases (all forms, excluding HIV) per 100 000 population': 'mortality_per100k_excl_hiv',\n",
    "        'Estimated number of deaths from TB in people who are HIV-positive': 'deaths_hiv_pos',\n",
    "        'Estimated mortality of TB cases who are HIV-positive, per 100 000 population': 'mortality_per100k_hiv_pos'\n",
    "    }\n",
    "    \n",
    "    # Apply column mapping for available columns\n",
    "    available_mappings = {old: new for old, new in column_mapping.items() if old in df.columns}\n",
    "    df = df.rename(columns=available_mappings)\n",
    "    \n",
    "    print(f\"\\n✓ Standardized {len(available_mappings)} column names\")\n",
    "    \n",
    "    # Data quality assessment\n",
    "    print(f\"\\nFirst 10 rows preview:\")\n",
    "    display_cols = ['country', 'iso3', 'region', 'year', 'population'] if all(c in df.columns for c in ['country', 'iso3', 'region', 'year', 'population']) else df.columns[:5]\n",
    "    print(df[display_cols].head(10).to_string())\n",
    "    \n",
    "    # Data types and missing values\n",
    "    print(f\"\\nData Types and Missing Values:\")\n",
    "    missing_summary = pd.DataFrame({\n",
    "        'dtype': df.dtypes,\n",
    "        'missing_count': df.isnull().sum(),\n",
    "        'missing_pct': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "    })\n",
    "    print(missing_summary[missing_summary['missing_count'] > 0].head(10))\n",
    "    \n",
    "    # Temporal coverage\n",
    "    if 'year' in df.columns:\n",
    "        years = pd.to_numeric(df['year'], errors='coerce').dropna()\n",
    "        print(f\"\\nTemporal Coverage: {years.min():.0f} - {years.max():.0f} ({years.nunique()} unique years)\")\n",
    "    \n",
    "    # Geographic coverage\n",
    "    if 'country' in df.columns:\n",
    "        countries = df['country'].nunique()\n",
    "        print(f\"Geographic Coverage: {countries} unique countries/territories\")\n",
    "        print(f\"Top 10 countries by data availability:\")\n",
    "        country_counts = df['country'].value_counts().head(10)\n",
    "        for country, count in country_counts.items():\n",
    "            print(f\"  • {country}: {count} records\")\n",
    "    \n",
    "    # Identify potential data quality issues\n",
    "    print(f\"\\nData Quality Checks:\")\n",
    "    \n",
    "    if 'population' in df.columns:\n",
    "        pop_issues = df[pd.to_numeric(df['population'], errors='coerce') <= 0]\n",
    "        print(f\"  • Records with invalid population: {len(pop_issues)}\")\n",
    "    \n",
    "    # Check for duplicate records\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"  • Exact duplicate rows: {duplicates}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the dataset\n",
    "df_raw = load_and_inspect_data('TB_Burden_Country.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150df83c",
   "metadata": {},
   "source": [
    "## Data Preparation & Cleaning\n",
    "\n",
    "Comprehensive data cleaning pipeline with automatic ISO code generation, outlier detection, and derived variable creation. All transformations are documented and logged for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73bdad08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEANING & TRANSFORMATION LOG\n",
      "==================================================\n",
      "✓ Removed 0 exact duplicate rows\n",
      "✓ Converted population from int64 to numeric\n",
      "✓ Converted incidence_per100k from float64 to numeric\n",
      "✓ Converted incidence_cases from float64 to numeric\n",
      "✓ Converted prevalence_per100k from float64 to numeric\n",
      "✓ Converted prevalence_cases from float64 to numeric\n",
      "✓ Converted deaths_excl_hiv from float64 to numeric\n",
      "✓ Converted mortality_per100k_excl_hiv from float64 to numeric\n",
      "✓ Converted deaths_hiv_pos from float64 to numeric\n",
      "✓ Converted mortality_per100k_hiv_pos from float64 to numeric\n",
      "✓ Converted year to integer type\n",
      "⚠ Flagged 117 potential outliers in incidence_per100k\n",
      "⚠ Flagged 73 potential outliers in prevalence_per100k\n",
      "⚠ Flagged 188 potential outliers in mortality_per100k_excl_hiv\n",
      "\n",
      "Post-cleaning validation:\n",
      "  • Final dataset shape: (5120, 50)\n",
      "  • Records with valid population: 5,120\n",
      "  • Records with valid incidence data: 5,120\n",
      "  • Year range: 1990 - 2013\n",
      "  • Countries with ISO3 codes: 5120\n"
     ]
    }
   ],
   "source": [
    "def clean_and_transform_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Comprehensive data cleaning and transformation pipeline\n",
    "    \"\"\"\n",
    "    print(\"CLEANING & TRANSFORMATION LOG\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # 1. Remove exact duplicates\n",
    "    initial_rows = len(df_clean)\n",
    "    df_clean = df_clean.drop_duplicates()\n",
    "    duplicates_removed = initial_rows - len(df_clean)\n",
    "    print(f\"✓ Removed {duplicates_removed} exact duplicate rows\")\n",
    "    \n",
    "    # 2. Convert numeric columns with error handling\n",
    "    numeric_columns = ['population', 'incidence_per100k', 'incidence_cases', \n",
    "                      'prevalence_per100k', 'prevalence_cases', 'deaths_excl_hiv',\n",
    "                      'mortality_per100k_excl_hiv', 'deaths_hiv_pos', 'mortality_per100k_hiv_pos']\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        if col in df_clean.columns:\n",
    "            original_type = df_clean[col].dtype\n",
    "            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "            print(f\"✓ Converted {col} from {original_type} to numeric\")\n",
    "    \n",
    "    # 3. Convert year to integer\n",
    "    if 'year' in df_clean.columns:\n",
    "        df_clean['year'] = pd.to_numeric(df_clean['year'], errors='coerce').astype('Int64')\n",
    "        print(f\"✓ Converted year to integer type\")\n",
    "    \n",
    "    # 4. Generate missing ISO codes using pycountry\n",
    "    def get_iso3_code(country_name: str) -> Optional[str]:\n",
    "        \"\"\"Fuzzy match country name to ISO3 code\"\"\"\n",
    "        if pd.isna(country_name):\n",
    "            return None\n",
    "            \n",
    "        # Direct lookup\n",
    "        try:\n",
    "            country = pycountry.countries.lookup(country_name)\n",
    "            return country.alpha_3\n",
    "        except LookupError:\n",
    "            pass\n",
    "        \n",
    "        # Manual mappings for common problematic cases\n",
    "        manual_mappings = {\n",
    "            'Bolivia (Plurinational State of)': 'BOL',\n",
    "            'Iran (Islamic Republic of)': 'IRN', \n",
    "            'Venezuela (Bolivarian Republic of)': 'VEN',\n",
    "            'Tanzania (United Republic of)': 'TZA',\n",
    "            'Democratic Republic of the Congo': 'COD',\n",
    "            'Republic of Korea': 'KOR',\n",
    "            'Russian Federation': 'RUS',\n",
    "            'United Kingdom of Great Britain and Northern Ireland': 'GBR',\n",
    "            'United States of America': 'USA',\n",
    "            'Viet Nam': 'VNM'\n",
    "        }\n",
    "        \n",
    "        if country_name in manual_mappings:\n",
    "            return manual_mappings[country_name]\n",
    "        \n",
    "        # Fuzzy matching attempts\n",
    "        for country in pycountry.countries:\n",
    "            if country_name.lower() in country.name.lower():\n",
    "                return country.alpha_3\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    # Apply ISO3 code generation if missing\n",
    "    if 'iso3' in df_clean.columns:\n",
    "        missing_iso3 = df_clean['iso3'].isna()\n",
    "        if missing_iso3.any():\n",
    "            print(f\"✓ Attempting to generate {missing_iso3.sum()} missing ISO3 codes\")\n",
    "            df_clean.loc[missing_iso3, 'iso3'] = df_clean.loc[missing_iso3, 'country'].apply(get_iso3_code)\n",
    "            \n",
    "            still_missing = df_clean['iso3'].isna().sum()\n",
    "            if still_missing > 0:\n",
    "                print(f\"⚠ Could not resolve {still_missing} ISO3 codes:\")\n",
    "                missing_countries = df_clean[df_clean['iso3'].isna()]['country'].unique()[:5]\n",
    "                for country in missing_countries:\n",
    "                    print(f\"    • {country}\")\n",
    "    \n",
    "    # 5. Calculate derived metrics\n",
    "    if 'population' in df_clean.columns:\n",
    "        # Only calculate rates where population data is available and valid\n",
    "        valid_pop = (df_clean['population'].notna()) & (df_clean['population'] > 0)\n",
    "        \n",
    "        # Calculate incidence rate if absolute numbers available\n",
    "        if 'incidence_cases' in df_clean.columns and 'incidence_per100k' not in df_clean.columns:\n",
    "            df_clean.loc[valid_pop, 'incidence_per100k'] = (\n",
    "                df_clean.loc[valid_pop, 'incidence_cases'] / df_clean.loc[valid_pop, 'population'] * 100000\n",
    "            )\n",
    "            print(\"✓ Calculated incidence_per100k from absolute cases\")\n",
    "        \n",
    "        # Calculate prevalence rate if absolute numbers available  \n",
    "        if 'prevalence_cases' in df_clean.columns and 'prevalence_per100k' not in df_clean.columns:\n",
    "            df_clean.loc[valid_pop, 'prevalence_per100k'] = (\n",
    "                df_clean.loc[valid_pop, 'prevalence_cases'] / df_clean.loc[valid_pop, 'population'] * 100000\n",
    "            )\n",
    "            print(\"✓ Calculated prevalence_per100k from absolute cases\")\n",
    "        \n",
    "        # Calculate mortality rate if absolute numbers available\n",
    "        if 'deaths_excl_hiv' in df_clean.columns and 'mortality_per100k_excl_hiv' not in df_clean.columns:\n",
    "            df_clean.loc[valid_pop, 'mortality_per100k_excl_hiv'] = (\n",
    "                df_clean.loc[valid_pop, 'deaths_excl_hiv'] / df_clean.loc[valid_pop, 'population'] * 100000\n",
    "            )\n",
    "            print(\"✓ Calculated mortality_per100k_excl_hiv from absolute deaths\")\n",
    "    \n",
    "    # 6. Outlier detection and flagging (not removal)\n",
    "    outlier_flags = {}\n",
    "    \n",
    "    for col in ['incidence_per100k', 'prevalence_per100k', 'mortality_per100k_excl_hiv']:\n",
    "        if col in df_clean.columns:\n",
    "            Q1 = df_clean[col].quantile(0.25)\n",
    "            Q3 = df_clean[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            \n",
    "            # Flag extreme outliers (beyond 3 * IQR)\n",
    "            lower_bound = Q1 - 3 * IQR\n",
    "            upper_bound = Q3 + 3 * IQR\n",
    "            \n",
    "            outliers = (df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)\n",
    "            outlier_flags[f'{col}_outlier'] = outliers\n",
    "            \n",
    "            if outliers.any():\n",
    "                print(f\"⚠ Flagged {outliers.sum()} potential outliers in {col}\")\n",
    "    \n",
    "    # Add outlier flags as columns\n",
    "    for flag_name, flag_values in outlier_flags.items():\n",
    "        df_clean[flag_name] = flag_values\n",
    "    \n",
    "    # 7. Data validation checks\n",
    "    print(f\"\\nPost-cleaning validation:\")\n",
    "    print(f\"  • Final dataset shape: {df_clean.shape}\")\n",
    "    print(f\"  • Records with valid population: {(df_clean['population'] > 0).sum():,}\")\n",
    "    \n",
    "    if 'incidence_per100k' in df_clean.columns:\n",
    "        valid_incidence = df_clean['incidence_per100k'].notna().sum()\n",
    "        print(f\"  • Records with valid incidence data: {valid_incidence:,}\")\n",
    "    \n",
    "    print(f\"  • Year range: {df_clean['year'].min()} - {df_clean['year'].max()}\")\n",
    "    print(f\"  • Countries with ISO3 codes: {df_clean['iso3'].notna().sum()}\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Apply cleaning and transformation\n",
    "df_clean = clean_and_transform_data(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "203f946f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved cleaned dataset to data/TB_Burden_Country_clean.csv\n",
      "  Shape: (5120, 50)\n",
      "  Size: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataset\n",
    "df_clean.to_csv('data/TB_Burden_Country_clean.csv', index=False)\n",
    "print(f\"✓ Saved cleaned dataset to data/TB_Burden_Country_clean.csv\")\n",
    "print(f\"  Shape: {df_clean.shape}\")\n",
    "print(f\"  Size: {os.path.getsize('data/TB_Burden_Country_clean.csv') / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deeda60",
   "metadata": {},
   "source": [
    "## Visualization Generation\n",
    "\n",
    "Creating publication-quality visualizations using colorblind-safe palettes and consistent design principles. Each visualization addresses specific analytical questions about global TB burden patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a6b2ef2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\n\nKaleido requires Google Chrome to be installed.\n\nEither download and install Chrome yourself following Google's instructions for your operating system,\nor install it from your terminal by running:\n\n    $ plotly_get_chrome\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mChromeNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[31mChromeNotFoundError\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mChromeNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\plotly\\io\\_kaleido.py:380\u001b[39m, in \u001b[36mto_image\u001b[39m\u001b[34m(fig, format, width, height, scale, validate, engine)\u001b[39m\n\u001b[32m    379\u001b[39m     \u001b[38;5;66;03m# TODO: Refactor to make it possible to use a shared Kaleido instance here\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m380\u001b[39m     img_bytes = \u001b[43mkaleido\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcalc_fig_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfig_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m            \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m            \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtopojson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtopojson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkopts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkopts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ChromeNotFoundError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\kaleido\\__init__.py:171\u001b[39m, in \u001b[36mcalc_fig_sync\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sync_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43moneshot_async_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalc_fig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\kaleido\\_sync_server.py:131\u001b[39m, in \u001b[36moneshot_async_run\u001b[39m\u001b[34m(func, args, kwargs)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m res\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\kaleido\\_sync_server.py:122\u001b[39m, in \u001b[36moneshot_async_run.<locals>.run\u001b[39m\u001b[34m(func, q, *args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     q.put(\u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# noqa: BLE001\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\asyncio\\runners.py:190\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\asyncio\\runners.py:118\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(self, coro, context)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.CancelledError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\asyncio\\base_events.py:654\u001b[39m, in \u001b[36mBaseEventLoop.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    652\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\kaleido\\__init__.py:101\u001b[39m, in \u001b[36mcalc_fig\u001b[39m\u001b[34m(fig, path, opts, topojson, kopts)\u001b[39m\n\u001b[32m    100\u001b[39m kopts[\u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# should we force this?\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mKaleido\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkopts\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m k:\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m k.calc_fig(\n\u001b[32m    103\u001b[39m         fig,\n\u001b[32m    104\u001b[39m         path=path,\n\u001b[32m    105\u001b[39m         opts=opts,\n\u001b[32m    106\u001b[39m         topojson=topojson,\n\u001b[32m    107\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\kaleido\\kaleido.py:155\u001b[39m, in \u001b[36mKaleido.__init__\u001b[39m\u001b[34m(self, page_generator, n, timeout, width, height, stepper, plotlyjs, mathjax, *args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ChromeNotFoundError:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ChromeNotFoundError(\n\u001b[32m    156\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mKaleido v1 and later requires Chrome to be installed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo install Chrome, use the CLI command `kaleido_get_chrome`, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor from Python, use either `kaleido.get_chrome()` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    159\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor `kaleido.get_chrome_sync()`.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    160\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mChromeNotFoundError\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# do this during open because it requires close\u001b[39;00m\n",
      "\u001b[31mChromeNotFoundError\u001b[39m: Kaleido v1 and later requires Chrome to be installed. To install Chrome, use the CLI command `kaleido_get_chrome`, or from Python, use either `kaleido.get_chrome()` or `kaleido.get_chrome_sync()`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Create and display choropleth map\u001b[39;00m\n\u001b[32m     51\u001b[39m latest_year = df_clean[\u001b[33m'\u001b[39m\u001b[33myear\u001b[39m\u001b[33m'\u001b[39m].max()\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m fig1 = \u001b[43mcreate_choropleth_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatest_year\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m fig1.show()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mcreate_choropleth_map\u001b[39m\u001b[34m(df, year)\u001b[39m\n\u001b[32m     31\u001b[39m fig.update_layout(\n\u001b[32m     32\u001b[39m     title_font_size=\u001b[32m20\u001b[39m,\n\u001b[32m     33\u001b[39m     title_x=\u001b[32m0.5\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     height=\u001b[32m700\u001b[39m\n\u001b[32m     42\u001b[39m )\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Save figure\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_image\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfigures/choropleth_incidence_per100k_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43myear\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.png\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✓ Saved choropleth map: figures/choropleth_incidence_per100k_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m fig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\plotly\\basedatatypes.py:3895\u001b[39m, in \u001b[36mBaseFigure.write_image\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3891\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   3892\u001b[39m         warnings.warn(\n\u001b[32m   3893\u001b[39m             ENGINE_PARAM_DEPRECATION_MSG, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m\n\u001b[32m   3894\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m3895\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\plotly\\io\\_kaleido.py:510\u001b[39m, in \u001b[36mwrite_image\u001b[39m\u001b[34m(fig, file, format, scale, width, height, validate, engine)\u001b[39m\n\u001b[32m    506\u001b[39m \u001b[38;5;28mformat\u001b[39m = infer_format(path, \u001b[38;5;28mformat\u001b[39m)\n\u001b[32m    508\u001b[39m \u001b[38;5;66;03m# Request image\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[38;5;66;03m# Do this first so we don't create a file if image conversion fails\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m img_data = \u001b[43mto_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[38;5;66;03m# Open file\u001b[39;00m\n\u001b[32m    521\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    522\u001b[39m     \u001b[38;5;66;03m# We previously failed to make sense of `file` as a pathlib object.\u001b[39;00m\n\u001b[32m    523\u001b[39m     \u001b[38;5;66;03m# Attempt to write to `file` as an open file descriptor.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\plotly\\io\\_kaleido.py:392\u001b[39m, in \u001b[36mto_image\u001b[39m\u001b[34m(fig, format, width, height, scale, validate, engine)\u001b[39m\n\u001b[32m    380\u001b[39m         img_bytes = kaleido.calc_fig_sync(\n\u001b[32m    381\u001b[39m             fig_dict,\n\u001b[32m    382\u001b[39m             opts=\u001b[38;5;28mdict\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    389\u001b[39m             kopts=kopts,\n\u001b[32m    390\u001b[39m         )\n\u001b[32m    391\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ChromeNotFoundError:\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(PLOTLY_GET_CHROME_ERROR_MSG)\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    395\u001b[39m     \u001b[38;5;66;03m# Kaleido v0\u001b[39;00m\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ENABLE_KALEIDO_V0_DEPRECATION_WARNINGS:\n",
      "\u001b[31mRuntimeError\u001b[39m: \n\nKaleido requires Google Chrome to be installed.\n\nEither download and install Chrome yourself following Google's instructions for your operating system,\nor install it from your terminal by running:\n\n    $ plotly_get_chrome\n\n"
     ]
    }
   ],
   "source": [
    "def create_choropleth_map(df: pd.DataFrame, year: int = None) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Create global choropleth map of TB incidence rates\n",
    "    \"\"\"\n",
    "    if year is None:\n",
    "        year = df['year'].max()\n",
    "    \n",
    "    # Filter data for the specified year\n",
    "    df_year = df[df['year'] == year].copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    df_year = df_year.dropna(subset=['incidence_per100k', 'iso3'])\n",
    "    \n",
    "    fig = px.choropleth(\n",
    "        df_year,\n",
    "        locations='iso3',\n",
    "        color='incidence_per100k',\n",
    "        hover_name='country',\n",
    "        hover_data={\n",
    "            'incidence_per100k': ':.1f',\n",
    "            'population': ':,',\n",
    "            'year': True,\n",
    "            'iso3': False\n",
    "        },\n",
    "        color_continuous_scale='Viridis',\n",
    "        labels={'incidence_per100k': 'TB Incidence per 100k'},\n",
    "        title=f'Global TB Incidence Rates per 100,000 Population ({year})',\n",
    "        projection='natural earth'\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_font_size=20,\n",
    "        title_x=0.5,\n",
    "        geo=dict(showframe=False, showcoastlines=True),\n",
    "        coloraxis_colorbar=dict(\n",
    "            title=\"Cases per<br>100,000\",\n",
    "            title_font_size=12,\n",
    "            tickfont_size=10\n",
    "        ),\n",
    "        width=1200,\n",
    "        height=700\n",
    "    )\n",
    "    \n",
    "    # Save figure\n",
    "    fig.write_image(f'figures/choropleth_incidence_per100k_{year}.png', scale=3)\n",
    "    print(f\"✓ Saved choropleth map: figures/choropleth_incidence_per100k_{year}.png\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display choropleth map\n",
    "latest_year = df_clean['year'].max()\n",
    "fig1 = create_choropleth_map(df_clean, latest_year)\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c6e98",
   "metadata": {},
   "source": [
    "### Global TB Incidence Distribution\n",
    "\n",
    "The choropleth map reveals stark geographical disparities in TB burden, with Sub-Saharan Africa and parts of Asia showing the highest incidence rates. This visualization enables immediate identification of priority regions requiring intensive intervention strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ad05ba3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\n\nKaleido requires Google Chrome to be installed.\n\nEither download and install Chrome yourself following Google's instructions for your operating system,\nor install it from your terminal by running:\n\n    $ plotly_get_chrome\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mChromeNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[31mChromeNotFoundError\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mChromeNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\plotly\\io\\_kaleido.py:380\u001b[39m, in \u001b[36mto_image\u001b[39m\u001b[34m(fig, format, width, height, scale, validate, engine)\u001b[39m\n\u001b[32m    379\u001b[39m     \u001b[38;5;66;03m# TODO: Refactor to make it possible to use a shared Kaleido instance here\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m380\u001b[39m     img_bytes = \u001b[43mkaleido\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcalc_fig_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfig_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m            \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m            \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtopojson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtopojson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkopts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkopts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ChromeNotFoundError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\kaleido\\__init__.py:171\u001b[39m, in \u001b[36mcalc_fig_sync\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sync_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43moneshot_async_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalc_fig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\kaleido\\_sync_server.py:131\u001b[39m, in \u001b[36moneshot_async_run\u001b[39m\u001b[34m(func, args, kwargs)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m res\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\kaleido\\_sync_server.py:122\u001b[39m, in \u001b[36moneshot_async_run.<locals>.run\u001b[39m\u001b[34m(func, q, *args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     q.put(\u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# noqa: BLE001\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\asyncio\\runners.py:190\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\asyncio\\runners.py:118\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(self, coro, context)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.CancelledError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\asyncio\\base_events.py:654\u001b[39m, in \u001b[36mBaseEventLoop.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    652\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\kaleido\\__init__.py:101\u001b[39m, in \u001b[36mcalc_fig\u001b[39m\u001b[34m(fig, path, opts, topojson, kopts)\u001b[39m\n\u001b[32m    100\u001b[39m kopts[\u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# should we force this?\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mKaleido\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkopts\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m k:\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m k.calc_fig(\n\u001b[32m    103\u001b[39m         fig,\n\u001b[32m    104\u001b[39m         path=path,\n\u001b[32m    105\u001b[39m         opts=opts,\n\u001b[32m    106\u001b[39m         topojson=topojson,\n\u001b[32m    107\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\kaleido\\kaleido.py:155\u001b[39m, in \u001b[36mKaleido.__init__\u001b[39m\u001b[34m(self, page_generator, n, timeout, width, height, stepper, plotlyjs, mathjax, *args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ChromeNotFoundError:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ChromeNotFoundError(\n\u001b[32m    156\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mKaleido v1 and later requires Chrome to be installed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo install Chrome, use the CLI command `kaleido_get_chrome`, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor from Python, use either `kaleido.get_chrome()` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    159\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor `kaleido.get_chrome_sync()`.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    160\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mChromeNotFoundError\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# do this during open because it requires close\u001b[39;00m\n",
      "\u001b[31mChromeNotFoundError\u001b[39m: Kaleido v1 and later requires Chrome to be installed. To install Chrome, use the CLI command `kaleido_get_chrome`, or from Python, use either `kaleido.get_chrome()` or `kaleido.get_chrome_sync()`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fig\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# Create and display top 10 bar chart\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m fig2 = \u001b[43mcreate_top10_bar_chart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatest_year\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m fig2.show()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mcreate_top10_bar_chart\u001b[39m\u001b[34m(df, year)\u001b[39m\n\u001b[32m     54\u001b[39m fig.update_layout(\n\u001b[32m     55\u001b[39m     title_font_size=\u001b[32m18\u001b[39m,\n\u001b[32m     56\u001b[39m     title_x=\u001b[32m0.5\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     62\u001b[39m     margin=\u001b[38;5;28mdict\u001b[39m(l=\u001b[32m150\u001b[39m, r=\u001b[32m50\u001b[39m, t=\u001b[32m80\u001b[39m, b=\u001b[32m50\u001b[39m)\n\u001b[32m     63\u001b[39m )\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Save figure\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_image\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfigures/top10_incidence_per100k_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43myear\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.png\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✓ Saved top 10 bar chart: figures/top10_incidence_per100k_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m fig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\plotly\\basedatatypes.py:3895\u001b[39m, in \u001b[36mBaseFigure.write_image\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3891\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   3892\u001b[39m         warnings.warn(\n\u001b[32m   3893\u001b[39m             ENGINE_PARAM_DEPRECATION_MSG, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m\n\u001b[32m   3894\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m3895\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\plotly\\io\\_kaleido.py:510\u001b[39m, in \u001b[36mwrite_image\u001b[39m\u001b[34m(fig, file, format, scale, width, height, validate, engine)\u001b[39m\n\u001b[32m    506\u001b[39m \u001b[38;5;28mformat\u001b[39m = infer_format(path, \u001b[38;5;28mformat\u001b[39m)\n\u001b[32m    508\u001b[39m \u001b[38;5;66;03m# Request image\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[38;5;66;03m# Do this first so we don't create a file if image conversion fails\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m img_data = \u001b[43mto_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[38;5;66;03m# Open file\u001b[39;00m\n\u001b[32m    521\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    522\u001b[39m     \u001b[38;5;66;03m# We previously failed to make sense of `file` as a pathlib object.\u001b[39;00m\n\u001b[32m    523\u001b[39m     \u001b[38;5;66;03m# Attempt to write to `file` as an open file descriptor.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\plotly\\io\\_kaleido.py:392\u001b[39m, in \u001b[36mto_image\u001b[39m\u001b[34m(fig, format, width, height, scale, validate, engine)\u001b[39m\n\u001b[32m    380\u001b[39m         img_bytes = kaleido.calc_fig_sync(\n\u001b[32m    381\u001b[39m             fig_dict,\n\u001b[32m    382\u001b[39m             opts=\u001b[38;5;28mdict\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    389\u001b[39m             kopts=kopts,\n\u001b[32m    390\u001b[39m         )\n\u001b[32m    391\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ChromeNotFoundError:\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(PLOTLY_GET_CHROME_ERROR_MSG)\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    395\u001b[39m     \u001b[38;5;66;03m# Kaleido v0\u001b[39;00m\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ENABLE_KALEIDO_V0_DEPRECATION_WARNINGS:\n",
      "\u001b[31mRuntimeError\u001b[39m: \n\nKaleido requires Google Chrome to be installed.\n\nEither download and install Chrome yourself following Google's instructions for your operating system,\nor install it from your terminal by running:\n\n    $ plotly_get_chrome\n\n"
     ]
    }
   ],
   "source": [
    "def create_top10_bar_chart(df: pd.DataFrame, year: int = None) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Create horizontal bar chart of top 10 countries by TB incidence rate\n",
    "    \"\"\"\n",
    "    if year is None:\n",
    "        year = df['year'].max()\n",
    "    \n",
    "    # Filter and prepare data\n",
    "    df_year = df[df['year'] == year].copy()\n",
    "    df_year = df_year.dropna(subset=['incidence_per100k', 'country'])\n",
    "    \n",
    "    # Get top 10 countries\n",
    "    top10 = df_year.nlargest(10, 'incidence_per100k')\n",
    "    \n",
    "    # Calculate 5-year change if available\n",
    "    year_5_ago = year - 5\n",
    "    if year_5_ago in df['year'].values:\n",
    "        df_5_ago = df[df['year'] == year_5_ago][['country', 'incidence_per100k']]\n",
    "        df_5_ago = df_5_ago.rename(columns={'incidence_per100k': 'incidence_5_ago'})\n",
    "        top10 = top10.merge(df_5_ago, on='country', how='left')\n",
    "        top10['pct_change_5yr'] = ((top10['incidence_per100k'] - top10['incidence_5_ago']) / \n",
    "                                  top10['incidence_5_ago'] * 100)\n",
    "    else:\n",
    "        top10['pct_change_5yr'] = np.nan\n",
    "    \n",
    "    # Create horizontal bar chart\n",
    "    fig = px.bar(\n",
    "        top10.sort_values('incidence_per100k'),\n",
    "        x='incidence_per100k',\n",
    "        y='country',\n",
    "        orientation='h',\n",
    "        color='incidence_per100k',\n",
    "        color_continuous_scale='Viridis',\n",
    "        title=f'Top 10 Countries by TB Incidence Rate ({year})',\n",
    "        labels={'incidence_per100k': 'TB Incidence per 100,000 Population'}\n",
    "    )\n",
    "    \n",
    "    # Add annotations for values and 5-year change\n",
    "    for i, (_, row) in enumerate(top10.sort_values('incidence_per100k').iterrows()):\n",
    "        annotation_text = f\"{row['incidence_per100k']:.0f}\"\n",
    "        if not np.isnan(row.get('pct_change_5yr', np.nan)):\n",
    "            change_sign = \"+\" if row['pct_change_5yr'] > 0 else \"\"\n",
    "            annotation_text += f\"<br>({change_sign}{row['pct_change_5yr']:.1f}% vs {year_5_ago})\"\n",
    "        \n",
    "        fig.add_annotation(\n",
    "            x=row['incidence_per100k'],\n",
    "            y=i,\n",
    "            text=annotation_text,\n",
    "            showarrow=False,\n",
    "            xanchor='left',\n",
    "            font=dict(size=10, color='white' if row['incidence_per100k'] > top10['incidence_per100k'].median() else 'black')\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_font_size=18,\n",
    "        title_x=0.5,\n",
    "        xaxis_title_font_size=12,\n",
    "        yaxis_title_font_size=12,\n",
    "        showlegend=False,\n",
    "        width=1000,\n",
    "        height=600,\n",
    "        margin=dict(l=150, r=50, t=80, b=50)\n",
    "    )\n",
    "    \n",
    "    # Save figure\n",
    "    fig.write_image(f'figures/top10_incidence_per100k_{year}.png', scale=3)\n",
    "    print(f\"✓ Saved top 10 bar chart: figures/top10_incidence_per100k_{year}.png\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display top 10 bar chart\n",
    "fig2 = create_top10_bar_chart(df_clean, latest_year)\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20c67a2",
   "metadata": {},
   "source": [
    "### Highest Burden Countries\n",
    "\n",
    "The horizontal bar chart highlights countries with the most severe TB burden per capita, enabling comparison of 5-year trends where data is available. This ranking helps prioritize resource allocation and intervention strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2f62de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trend_analysis(df: pd.DataFrame) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Create multi-line trend chart for top 5 countries by recent incidence\n",
    "    \"\"\"\n",
    "    latest_year = df['year'].max()\n",
    "    \n",
    "    # Get top 5 countries by latest year incidence\n",
    "    df_latest = df[df['year'] == latest_year].dropna(subset=['incidence_per100k', 'country'])\n",
    "    top5_countries = df_latest.nlargest(5, 'incidence_per100k')['country'].tolist()\n",
    "    \n",
    "    # Filter data for top 5 countries\n",
    "    df_trends = df[df['country'].isin(top5_countries)].copy()\n",
    "    df_trends = df_trends.dropna(subset=['incidence_per100k', 'year'])\n",
    "    df_trends = df_trends.sort_values(['country', 'year'])\n",
    "    \n",
    "    # Create line chart\n",
    "    fig = px.line(\n",
    "        df_trends,\n",
    "        x='year',\n",
    "        y='incidence_per100k',\n",
    "        color='country',\n",
    "        title='TB Incidence Trends: Top 5 Countries',\n",
    "        labels={\n",
    "            'incidence_per100k': 'TB Incidence per 100,000 Population',\n",
    "            'year': 'Year',\n",
    "            'country': 'Country'\n",
    "        },\n",
    "        color_discrete_sequence=px.colors.qualitative.Set1\n",
    "    )\n",
    "    \n",
    "    # Add start and end point annotations\n",
    "    for country in top5_countries:\n",
    "        country_data = df_trends[df_trends['country'] == country]\n",
    "        if len(country_data) > 0:\n",
    "            start_data = country_data.iloc[0]\n",
    "            end_data = country_data.iloc[-1]\n",
    "            \n",
    "            # Start point annotation\n",
    "            fig.add_annotation(\n",
    "                x=start_data['year'],\n",
    "                y=start_data['incidence_per100k'],\n",
    "                text=f\"{start_data['incidence_per100k']:.0f}\",\n",
    "                showarrow=True,\n",
    "                arrowhead=2,\n",
    "                arrowsize=1,\n",
    "                arrowwidth=1,\n",
    "                arrowcolor=\"gray\",\n",
    "                font=dict(size=10)\n",
    "            )\n",
    "            \n",
    "            # End point annotation\n",
    "            fig.add_annotation(\n",
    "                x=end_data['year'],\n",
    "                y=end_data['incidence_per100k'],\n",
    "                text=f\"{end_data['incidence_per100k']:.0f}\",\n",
    "                showarrow=True,\n",
    "                arrowhead=2,\n",
    "                arrowsize=1,\n",
    "                arrowwidth=1,\n",
    "                arrowcolor=\"gray\",\n",
    "                font=dict(size=10)\n",
    "            )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_font_size=18,\n",
    "        title_x=0.5,\n",
    "        xaxis_title_font_size=12,\n",
    "        yaxis_title_font_size=12,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"right\",\n",
    "            x=1\n",
    "        ),\n",
    "        width=1000,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.update_traces(line=dict(width=3), marker=dict(size=6))\n",
    "    \n",
    "    # Save figure\n",
    "    fig.write_image('figures/trends_top5.png', scale=3)\n",
    "    print(\"✓ Saved trend analysis: figures/trends_top5.png\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display trend analysis\n",
    "fig3 = create_trend_analysis(df_clean)\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c82e38a",
   "metadata": {},
   "source": [
    "### Temporal Trends Analysis  \n",
    "\n",
    "The multi-line trend chart reveals divergent trajectories among high-burden countries, with some showing declining trends while others remain stable or increasing. Start and end point annotations facilitate quick assessment of progress over the observation period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b56ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regional_stacked_area(df: pd.DataFrame) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Create stacked area chart showing regional composition over time\n",
    "    \"\"\"\n",
    "    # Prepare regional aggregation\n",
    "    df_regional = df.dropna(subset=['region', 'year', 'incidence_cases'])\n",
    "    \n",
    "    # Map common region abbreviations to full names\n",
    "    region_mapping = {\n",
    "        'AFR': 'Africa', 'AMR': 'Americas', 'EMR': 'Eastern Mediterranean',\n",
    "        'EUR': 'Europe', 'SEA': 'South-East Asia', 'WPR': 'Western Pacific'\n",
    "    }\n",
    "    \n",
    "    df_regional['region_full'] = df_regional['region'].map(region_mapping).fillna(df_regional['region'])\n",
    "    \n",
    "    # Aggregate by region and year (using absolute cases for composition)\n",
    "    regional_summary = df_regional.groupby(['year', 'region_full'])['incidence_cases'].sum().reset_index()\n",
    "    \n",
    "    # Create stacked area chart\n",
    "    fig = px.area(\n",
    "        regional_summary,\n",
    "        x='year',\n",
    "        y='incidence_cases',\n",
    "        color='region_full',\n",
    "        title='Global TB Incidence by WHO Region (Absolute Cases)',\n",
    "        labels={\n",
    "            'incidence_cases': 'Total TB Cases',\n",
    "            'year': 'Year',\n",
    "            'region_full': 'WHO Region'\n",
    "        },\n",
    "        color_discrete_sequence=px.colors.qualitative.Set2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_font_size=18,\n",
    "        title_x=0.5,\n",
    "        xaxis_title_font_size=12,\n",
    "        yaxis_title_font_size=12,\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"top\",\n",
    "            y=0.99,\n",
    "            xanchor=\"left\",\n",
    "            x=1.02\n",
    "        ),\n",
    "        width=1000,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    # Format y-axis to show values in millions\n",
    "    fig.update_yaxis(tickformat='.2s')\n",
    "    \n",
    "    # Save figure\n",
    "    fig.write_image('figures/stacked_area_region.png', scale=3)\n",
    "    print(\"✓ Saved regional stacked area chart: figures/stacked_area_region.png\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display regional stacked area chart\n",
    "fig4 = create_regional_stacked_area(df_clean)\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32350f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regional_heatmap(df: pd.DataFrame) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Create heatmap showing median incidence rates by region and year\n",
    "    \"\"\"\n",
    "    # Prepare data for heatmap\n",
    "    df_heatmap = df.dropna(subset=['region', 'year', 'incidence_per100k'])\n",
    "    \n",
    "    # Map region codes to full names\n",
    "    region_mapping = {\n",
    "        'AFR': 'Africa', 'AMR': 'Americas', 'EMR': 'E. Mediterranean',\n",
    "        'EUR': 'Europe', 'SEA': 'SE Asia', 'WPR': 'W. Pacific'\n",
    "    }\n",
    "    df_heatmap['region_full'] = df_heatmap['region'].map(region_mapping).fillna(df_heatmap['region'])\n",
    "    \n",
    "    # Calculate median incidence by region and year\n",
    "    heatmap_data = df_heatmap.groupby(['region_full', 'year'])['incidence_per100k'].median().reset_index()\n",
    "    heatmap_pivot = heatmap_data.pivot(index='region_full', columns='year', values='incidence_per100k')\n",
    "    \n",
    "    # Create matplotlib figure for better heatmap control\n",
    "    fig, ax = plt.subplots(figsize=(16, 6))\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(\n",
    "        heatmap_pivot,\n",
    "        annot=False,\n",
    "        cmap='viridis',\n",
    "        cbar_kws={\n",
    "            'label': 'Median TB Incidence per 100k',\n",
    "            'shrink': 0.8\n",
    "        },\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_title('TB Incidence Heatmap: Regional Medians by Year', fontsize=16, pad=20)\n",
    "    ax.set_xlabel('Year', fontsize=12)\n",
    "    ax.set_ylabel('WHO Region', fontsize=12)\n",
    "    \n",
    "    # Rotate x-axis labels for better readability\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig('figures/heatmap_region_year.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"✓ Saved regional heatmap: figures/heatmap_region_year.png\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display regional heatmap\n",
    "fig5 = create_regional_heatmap(df_clean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5069e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_incidence_mortality_scatter(df: pd.DataFrame) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Create scatter plot of incidence vs mortality rates with regression line\n",
    "    \"\"\"\n",
    "    # Prepare data for latest year with both metrics\n",
    "    latest_year = df['year'].max() \n",
    "    df_scatter = df[df['year'] == latest_year].copy()\n",
    "    df_scatter = df_scatter.dropna(subset=['incidence_per100k', 'mortality_per100k_excl_hiv', 'population', 'region'])\n",
    "    \n",
    "    # Map region codes for better display\n",
    "    region_mapping = {\n",
    "        'AFR': 'Africa', 'AMR': 'Americas', 'EMR': 'E. Mediterranean',\n",
    "        'EUR': 'Europe', 'SEA': 'SE Asia', 'WPR': 'W. Pacific'\n",
    "    }\n",
    "    df_scatter['region_full'] = df_scatter['region'].map(region_mapping).fillna(df_scatter['region'])\n",
    "    \n",
    "    # Calculate log population for sizing\n",
    "    df_scatter['log_population'] = np.log10(df_scatter['population'])\n",
    "    \n",
    "    # Create scatter plot\n",
    "    fig = px.scatter(\n",
    "        df_scatter,\n",
    "        x='incidence_per100k',\n",
    "        y='mortality_per100k_excl_hiv',\n",
    "        color='region_full',\n",
    "        size='log_population',\n",
    "        hover_name='country',\n",
    "        hover_data={\n",
    "            'incidence_per100k': ':.1f',\n",
    "            'mortality_per100k_excl_hiv': ':.1f',\n",
    "            'population': ':,',\n",
    "            'log_population': False\n",
    "        },\n",
    "        title=f'TB Incidence vs Mortality Rates by Region ({latest_year})',\n",
    "        labels={\n",
    "            'incidence_per100k': 'TB Incidence per 100,000',\n",
    "            'mortality_per100k_excl_hiv': 'TB Mortality per 100,000 (excl. HIV)',\n",
    "            'region_full': 'WHO Region'\n",
    "        },\n",
    "        color_discrete_sequence=px.colors.qualitative.Set1\n",
    "    )\n",
    "    \n",
    "    # Add regression line\n",
    "    from scipy import stats\n",
    "    \n",
    "    # Calculate regression\n",
    "    valid_data = df_scatter[['incidence_per100k', 'mortality_per100k_excl_hiv']].dropna()\n",
    "    if len(valid_data) > 1:\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
    "            valid_data['incidence_per100k'], \n",
    "            valid_data['mortality_per100k_excl_hiv']\n",
    "        )\n",
    "        \n",
    "        # Create regression line points\n",
    "        x_range = np.linspace(valid_data['incidence_per100k'].min(), valid_data['incidence_per100k'].max(), 100)\n",
    "        y_pred = slope * x_range + intercept\n",
    "        \n",
    "        # Add regression line\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_range,\n",
    "                y=y_pred,\n",
    "                mode='lines',\n",
    "                name=f'Regression Line (R² = {r_value**2:.3f})',\n",
    "                line=dict(color='red', width=2, dash='dash'),\n",
    "                showlegend=True\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Add R² annotation\n",
    "        fig.add_annotation(\n",
    "            x=valid_data['incidence_per100k'].quantile(0.1),\n",
    "            y=valid_data['mortality_per100k_excl_hiv'].quantile(0.9),\n",
    "            text=f\"R² = {r_value**2:.3f}<br>p < 0.001\" if p_value < 0.001 else f\"R² = {r_value**2:.3f}<br>p = {p_value:.3f}\",\n",
    "            showarrow=False,\n",
    "            bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "            bordercolor=\"black\",\n",
    "            borderwidth=1\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_font_size=18,\n",
    "        title_x=0.5,\n",
    "        xaxis_title_font_size=12,\n",
    "        yaxis_title_font_size=12,\n",
    "        width=1000,\n",
    "        height=600,\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"top\",\n",
    "            y=0.99,\n",
    "            xanchor=\"left\",\n",
    "            x=1.02\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Save figure\n",
    "    fig.write_image('figures/scatter_incidence_vs_deaths.png', scale=3)\n",
    "    print(\"✓ Saved incidence vs mortality scatter plot: figures/scatter_incidence_vs_deaths.png\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display scatter plot\n",
    "fig6 = create_incidence_mortality_scatter(df_clean)\n",
    "fig6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc0fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_demographic_analysis(df: pd.DataFrame) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Create demographic analysis - placeholder since sex/age data not available in this dataset\n",
    "    \"\"\"\n",
    "    # Check for demographic columns\n",
    "    demographic_cols = ['sex', 'age_group', 'gender', 'age']\n",
    "    available_demos = [col for col in demographic_cols if col in df.columns]\n",
    "    \n",
    "    if not available_demos:\n",
    "        # Create placeholder figure noting absence of demographic data\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        fig.add_annotation(\n",
    "            x=0.5,\n",
    "            y=0.5,\n",
    "            text=\"Demographic Analysis Unavailable<br><br>\" +\n",
    "                 \"The current dataset does not contain<br>\" +\n",
    "                 \"sex or age group stratification data.<br><br>\" +\n",
    "                 \"Future analyses would benefit from<br>\" +\n",
    "                 \"age- and sex-disaggregated TB burden data<br>\" +\n",
    "                 \"to identify vulnerable populations.\",\n",
    "            showarrow=False,\n",
    "            font=dict(size=16),\n",
    "            align=\"center\",\n",
    "            bgcolor=\"rgba(240,240,240,0.8)\",\n",
    "            bordercolor=\"gray\",\n",
    "            borderwidth=2,\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\"\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=\"Demographic Analysis: Data Not Available\",\n",
    "            title_font_size=18,\n",
    "            title_x=0.5,\n",
    "            xaxis=dict(showgrid=False, showticklabels=False),\n",
    "            yaxis=dict(showgrid=False, showticklabels=False),\n",
    "            width=800,\n",
    "            height=400,\n",
    "            plot_bgcolor='white'\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        # If demographic data were available, create small multiples here\n",
    "        # This is placeholder code for potential future enhancement\n",
    "        fig = go.Figure()\n",
    "    \n",
    "    # Save figure\n",
    "    fig.write_image('figures/small_multiples_demographics.png', scale=3)\n",
    "    print(\"✓ Saved demographic analysis placeholder: figures/small_multiples_demographics.png\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create demographic analysis\n",
    "fig7 = create_demographic_analysis(df_clean)\n",
    "fig7.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96681c9c",
   "metadata": {},
   "source": [
    "## Visual Design Elements & Course Alignment\n",
    "\n",
    "### Palette Justification\n",
    "**Viridis Sequential Palette**: Selected for its perceptual uniformity and colorblind accessibility. The viridis scale provides consistent lightness gradients that maintain data relationships when converted to grayscale, essential for publication accessibility.\n",
    "\n",
    "**Set1 Qualitative Palette**: Used for categorical regional comparisons, providing maximum perceptual distance between categories while maintaining aesthetic coherence.\n",
    "\n",
    "### Design Rationale & Course Topic Mapping\n",
    "\n",
    "| Visualization | Course Topic | Design Choice | Analytical Purpose |\n",
    "|---------------|--------------|---------------|--------------------|\n",
    "| Choropleth Map | **Chart Types, Tools** | Natural Earth projection, sequential color mapping | Global pattern identification, geographic disparities |\n",
    "| Horizontal Bar Chart | **Visual Elements, Data Prep** | Ascending sort, dual annotations (current + trend) | Ranking with temporal context |\n",
    "| Multi-line Trends | **Advanced Techniques** | Annotated endpoints, consistent line weights | Temporal trajectory comparison |\n",
    "| Stacked Area | **Chart Types** | Regional composition over time | Proportional burden assessment |\n",
    "| Heatmap | **Visual Elements** | Matrix encoding, median aggregation | Regional-temporal pattern detection |\n",
    "| Scatter Plot | **Advanced, Tools** | Regression overlay, size/color encoding | Correlation analysis with contextual dimensions |\n",
    "\n",
    "### Accessibility & Ethical Considerations\n",
    "\n",
    "**Data Provenance**: WHO TB burden estimates combine surveillance data with mathematical models. Users must understand that estimates for high-burden, low-surveillance countries carry higher uncertainty.\n",
    "\n",
    "**Representational Fairness**: Per-capita rates (per 100,000) ensure fair comparison across countries of different sizes, avoiding bias toward absolute case counts that would overrepresent large populations.\n",
    "\n",
    "**Potential Misinterpretation**: Choropleth maps can create false geographic continuity impressions. Readers should interpret patterns as country-level data points, not regional continua."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4c9a82",
   "metadata": {},
   "source": [
    "## Export & PDF Generation\n",
    "\n",
    "Converting notebook to PDF format for submission using nbconvert and ensuring A4 compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b3f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_pdf():\n",
    "    \"\"\"\n",
    "    Export notebook to PDF using nbconvert\n",
    "    \"\"\"\n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    try:\n",
    "        # Convert notebook to HTML first for better control\n",
    "        cmd_html = [\n",
    "            sys.executable, '-m', 'jupyter', 'nbconvert',\n",
    "            '--to', 'html',\n",
    "            '--output-dir', 'report',\n",
    "            '--output', 'MCSC2108_TB_Burden_Report',\n",
    "            'notebooks/TB_Burden_Report.ipynb'\n",
    "        ]\n",
    "        \n",
    "        print(\"Converting notebook to HTML...\")\n",
    "        result_html = subprocess.run(cmd_html, capture_output=True, text=True)\n",
    "        \n",
    "        if result_html.returncode == 0:\n",
    "            print(\"✓ HTML conversion successful\")\n",
    "            \n",
    "            # Convert HTML to PDF\n",
    "            cmd_pdf = [\n",
    "                sys.executable, '-m', 'jupyter', 'nbconvert',\n",
    "                '--to', 'pdf',\n",
    "                '--output-dir', 'report', \n",
    "                '--output', 'MCSC2108_TB_Burden_Report',\n",
    "                'notebooks/TB_Burden_Report.ipynb'\n",
    "            ]\n",
    "            \n",
    "            print(\"Converting notebook to PDF...\")\n",
    "            result_pdf = subprocess.run(cmd_pdf, capture_output=True, text=True)\n",
    "            \n",
    "            if result_pdf.returncode == 0:\n",
    "                print(\"✓ PDF conversion successful\")\n",
    "                print(\"✓ Final report saved to: report/MCSC2108_TB_Burden_Report.pdf\")\n",
    "            else:\n",
    "                print(f\"❌ PDF conversion failed: {result_pdf.stderr}\")\n",
    "                print(\"Alternative: Use browser 'Print to PDF' from the HTML version\")\n",
    "        else:\n",
    "            print(f\"❌ HTML conversion failed: {result_html.stderr}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Export failed: {str(e)}\")\n",
    "        print(\"\\nManual export instructions:\")\n",
    "        print(\"1. File → Download as → PDF via LaTeX (.pdf)\")\n",
    "        print(\"2. Or: jupyter nbconvert --to pdf notebooks/TB_Burden_Report.ipynb --output-dir report\")\n",
    "        print(\"3. Or: Print to PDF from browser after HTML conversion\")\n",
    "\n",
    "# Create final summary and export\n",
    "print(\"=\"*80)\n",
    "print(\"REPRODUCIBLE EXPORT SUMMARY\")  \n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📊 Figures Generated:\")\n",
    "figure_files = [\n",
    "    f'figures/choropleth_incidence_per100k_{latest_year}.png',\n",
    "    f'figures/top10_incidence_per100k_{latest_year}.png',\n",
    "    'figures/trends_top5.png',\n",
    "    'figures/stacked_area_region.png', \n",
    "    'figures/heatmap_region_year.png',\n",
    "    'figures/scatter_incidence_vs_deaths.png',\n",
    "    'figures/small_multiples_demographics.png'\n",
    "]\n",
    "\n",
    "for fig_file in figure_files:\n",
    "    if os.path.exists(fig_file):\n",
    "        size_kb = os.path.getsize(fig_file) / 1024\n",
    "        print(f\"  ✓ {fig_file} ({size_kb:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"  ❌ {fig_file} (missing)\")\n",
    "\n",
    "print(f\"\\n📁 Data Files:\")\n",
    "if os.path.exists('data/TB_Burden_Country_clean.csv'):\n",
    "    size_mb = os.path.getsize('data/TB_Burden_Country_clean.csv') / 1024**2\n",
    "    print(f\"  ✓ data/TB_Burden_Country_clean.csv ({size_mb:.1f} MB)\")\n",
    "\n",
    "print(f\"\\n🎓 Report Generation:\")\n",
    "export_to_pdf()\n",
    "\n",
    "print(f\"\\n✅ Analysis Complete!\")\n",
    "print(f\"   • Author: Daniel Wanjal Machimbo\")\n",
    "print(f\"   • Course: MCSC 2108 Data Visualization\") \n",
    "print(f\"   • Institution: The Cooperative University of Kenya\")\n",
    "print(f\"   • Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
